{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from numpy import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from numpy import matlib\n",
    "import qgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/CTG.xls', sheet_name='Raw Data', header=0, skiprows=[1])\n",
    "data = df.to_numpy()\n",
    "# Features matrix\n",
    "X = data[:,0:22]\n",
    "Y = data[:,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redes_neuronales(neuronas, capas_ocultas):\n",
    "    capas = (neuronas)\n",
    "    if capas_ocultas == 2:\n",
    "        capas = (neuronas,neuronas)\n",
    "    elif capas_ocultas == 3:\n",
    "        capas = (neuronas,neuronas,neuronas)\n",
    "    elif capas_ocultas == 4:\n",
    "        capas = (neuronas,neuronas,neuronas,neuronas)\n",
    "    elif capas_ocultas == 5:\n",
    "        capas = (neuronas,neuronas,neuronas,neuronas,neuronas)\n",
    "    elif capas_ocultas == 6:\n",
    "        capas = (neuronas,neuronas,neuronas,neuronas,neuronas,neuronas)        \n",
    "        \n",
    "    Folds = 4\n",
    "    random.seed(19680801)\n",
    "    EficienciaTrain = np.zeros(Folds)\n",
    "    EficienciaVal = np.zeros(Folds)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=Folds)\n",
    "    j = 0\n",
    "    for train, test in skf.split(X, Y):\n",
    "        Xtrain = X[train,:]\n",
    "        Ytrain = Y[train]\n",
    "        Xtest = X[test,:]\n",
    "        Ytest = Y[test]\n",
    "        \n",
    "        #Se normalizan los datos\n",
    "        media = np.mean(Xtrain)\n",
    "        desvia = np.std(Xtrain)\n",
    "        Xtrain = preprocessing.scale(Xtrain)\n",
    "        Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "        \n",
    "        #Llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=capas,activation = 'relu',max_iter=1000)\n",
    "        mlp.fit(Xtrain,Ytrain)\n",
    "        \n",
    "        #Validación con las muestras de entrenamiento\n",
    "        Ytrain_pred = mlp.predict(Xtrain)\n",
    "\n",
    "        #Validación con las muestras de test    \n",
    "        Yest = mlp.predict(Xtest)\n",
    "           \n",
    "        #Evaluamos las predicciones del modelo con los datos de test\n",
    "        EficienciaTrain[j] = np.mean(Ytrain_pred == Ytrain)\n",
    "        EficienciaVal[j] = np.mean(Yest == Ytest)\n",
    "        j += 1\n",
    "    print(\"Modelo entrenado con \" + str(neuronas) + \" neuronas y con \" + str(capas_ocultas) + \" capas ocultas\" )    \n",
    "    \n",
    "    return np.mean(EficienciaVal), np.std(EficienciaVal),np.mean(EficienciaTrain),np.std(EficienciaTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_types = pd.DataFrame({\n",
    "    'N. de capas ocultas' : pd.Series([1,1,1,1,1,1,1,1,1,1,1,\n",
    "                                       2,2,2,2,2,2,2,2,2,2,2,\n",
    "                                       3,3,3,3,3,3,3,3,3,3,3,\n",
    "                                       4,4,4,4,4,4,4,4,4,4,4,\n",
    "                                       5,5,5,5,5,5,5,5,5,5,5]),\n",
    "    \n",
    "    'Neuronas por capa' : pd.Series([10,20,30,40,50,60,70,80,90,100,120,\n",
    "                                    10,20,30,40,50,60,70,80,90,100,120,\n",
    "                                    10,20,30,40,50,60,70,80,90,100,120,\n",
    "                                    10,20,30,40,50,60,70,80,90,100,120,\n",
    "                                    10,20,30,40,50,60,70,80,90,100,120])})\n",
    "df_types[\"Eficiencia en validacion\"] = \"\"\n",
    "df_types[\"IC Eficiencia en validacion\"] = \"\"\n",
    "df_types[\"Eficiencia en entrenamiento\"] = \"\"\n",
    "df_types[\"IC Eficiencia en entrenamiento\"] = \"\"\n",
    "df_types.set_index(['N. de capas ocultas','Neuronas por capa'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/my_env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo entrenado con 10 neuronas y con 1 capas ocultas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/my_env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/juan/anaconda3/envs/my_env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo entrenado con 20 neuronas y con 1 capas ocultas\n",
      "Modelo entrenado con 30 neuronas y con 1 capas ocultas\n",
      "Modelo entrenado con 40 neuronas y con 1 capas ocultas\n",
      "Modelo entrenado con 50 neuronas y con 1 capas ocultas\n",
      "Modelo entrenado con 60 neuronas y con 1 capas ocultas\n",
      "Modelo entrenado con 70 neuronas y con 1 capas ocultas\n",
      "Modelo entrenado con 80 neuronas y con 1 capas ocultas\n",
      "Modelo entrenado con 90 neuronas y con 1 capas ocultas\n",
      "Modelo entrenado con 100 neuronas y con 1 capas ocultas\n",
      "Modelo entrenado con 120 neuronas y con 1 capas ocultas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/my_env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/juan/anaconda3/envs/my_env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/juan/anaconda3/envs/my_env/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo entrenado con 10 neuronas y con 2 capas ocultas\n",
      "Modelo entrenado con 20 neuronas y con 2 capas ocultas\n",
      "Modelo entrenado con 30 neuronas y con 2 capas ocultas\n",
      "Modelo entrenado con 40 neuronas y con 2 capas ocultas\n",
      "Modelo entrenado con 50 neuronas y con 2 capas ocultas\n",
      "Modelo entrenado con 60 neuronas y con 2 capas ocultas\n",
      "Modelo entrenado con 70 neuronas y con 2 capas ocultas\n",
      "Modelo entrenado con 80 neuronas y con 2 capas ocultas\n",
      "Modelo entrenado con 90 neuronas y con 2 capas ocultas\n",
      "Modelo entrenado con 100 neuronas y con 2 capas ocultas\n",
      "Modelo entrenado con 120 neuronas y con 2 capas ocultas\n",
      "Modelo entrenado con 10 neuronas y con 3 capas ocultas\n",
      "Modelo entrenado con 20 neuronas y con 3 capas ocultas\n",
      "Modelo entrenado con 30 neuronas y con 3 capas ocultas\n",
      "Modelo entrenado con 40 neuronas y con 3 capas ocultas\n",
      "Modelo entrenado con 50 neuronas y con 3 capas ocultas\n",
      "Modelo entrenado con 60 neuronas y con 3 capas ocultas\n",
      "Modelo entrenado con 70 neuronas y con 3 capas ocultas\n",
      "Modelo entrenado con 80 neuronas y con 3 capas ocultas\n",
      "Modelo entrenado con 90 neuronas y con 3 capas ocultas\n",
      "Modelo entrenado con 100 neuronas y con 3 capas ocultas\n",
      "Modelo entrenado con 120 neuronas y con 3 capas ocultas\n",
      "Modelo entrenado con 10 neuronas y con 4 capas ocultas\n",
      "Modelo entrenado con 20 neuronas y con 4 capas ocultas\n",
      "Modelo entrenado con 30 neuronas y con 4 capas ocultas\n",
      "Modelo entrenado con 40 neuronas y con 4 capas ocultas\n",
      "Modelo entrenado con 50 neuronas y con 4 capas ocultas\n",
      "Modelo entrenado con 60 neuronas y con 4 capas ocultas\n",
      "Modelo entrenado con 70 neuronas y con 4 capas ocultas\n",
      "Modelo entrenado con 80 neuronas y con 4 capas ocultas\n",
      "Modelo entrenado con 90 neuronas y con 4 capas ocultas\n",
      "Modelo entrenado con 100 neuronas y con 4 capas ocultas\n",
      "Modelo entrenado con 120 neuronas y con 4 capas ocultas\n",
      "Modelo entrenado con 10 neuronas y con 5 capas ocultas\n",
      "Modelo entrenado con 20 neuronas y con 5 capas ocultas\n",
      "Modelo entrenado con 30 neuronas y con 5 capas ocultas\n",
      "Modelo entrenado con 40 neuronas y con 5 capas ocultas\n",
      "Modelo entrenado con 50 neuronas y con 5 capas ocultas\n",
      "Modelo entrenado con 60 neuronas y con 5 capas ocultas\n",
      "Modelo entrenado con 70 neuronas y con 5 capas ocultas\n",
      "Modelo entrenado con 80 neuronas y con 5 capas ocultas\n",
      "Modelo entrenado con 90 neuronas y con 5 capas ocultas\n",
      "Modelo entrenado con 100 neuronas y con 5 capas ocultas\n",
      "Modelo entrenado con 120 neuronas y con 5 capas ocultas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Eficiencia en validacion</th>\n",
       "      <th>IC Eficiencia en validacion</th>\n",
       "      <th>Eficiencia en entrenamiento</th>\n",
       "      <th>IC Eficiencia en entrenamiento</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N. de capas ocultas</th>\n",
       "      <th>Neuronas por capa</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">1</th>\n",
       "      <th>10</th>\n",
       "      <td>0.6652055633433868</td>\n",
       "      <td>0.19631049474871673</td>\n",
       "      <td>0.9628392915439167</td>\n",
       "      <td>0.006885487312743781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.7210168783540774</td>\n",
       "      <td>0.10206166629413553</td>\n",
       "      <td>0.9819681367825269</td>\n",
       "      <td>0.005294735088287567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.6683578650014868</td>\n",
       "      <td>0.12170345327133039</td>\n",
       "      <td>0.9909062393064901</td>\n",
       "      <td>0.000701363333026307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.7380262095917761</td>\n",
       "      <td>0.049824030633566996</td>\n",
       "      <td>0.9929435618679767</td>\n",
       "      <td>0.003022166742979009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.7092492884754259</td>\n",
       "      <td>0.11918509845590243</td>\n",
       "      <td>0.9924737357567366</td>\n",
       "      <td>0.002173441307030737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.7798672174787251</td>\n",
       "      <td>0.003578027555392126</td>\n",
       "      <td>0.995923388254544</td>\n",
       "      <td>0.0005439853757911653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.7855133950695949</td>\n",
       "      <td>0.005122875235273092</td>\n",
       "      <td>0.9941985620056404</td>\n",
       "      <td>0.002563238232641931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.775157349588661</td>\n",
       "      <td>0.012076023227392374</td>\n",
       "      <td>0.9938848857195675</td>\n",
       "      <td>0.002484238133809588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.7247904365433357</td>\n",
       "      <td>0.08697479667501404</td>\n",
       "      <td>0.9943557934731733</td>\n",
       "      <td>0.0011721983651877639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.7393510258697592</td>\n",
       "      <td>0.10664634172965395</td>\n",
       "      <td>0.9965503475021928</td>\n",
       "      <td>0.0011315215524325154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.7652809637087069</td>\n",
       "      <td>0.016623763106296735</td>\n",
       "      <td>0.9957661567870109</td>\n",
       "      <td>0.0020513461268557376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">2</th>\n",
       "      <th>10</th>\n",
       "      <td>0.6881805502456707</td>\n",
       "      <td>0.0936844064855061</td>\n",
       "      <td>0.986045338514728</td>\n",
       "      <td>0.0022804283621258126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.6843583181116634</td>\n",
       "      <td>0.10224190717606721</td>\n",
       "      <td>0.9951390008771137</td>\n",
       "      <td>0.0017959709781269419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.7775113985528794</td>\n",
       "      <td>0.020707196349633954</td>\n",
       "      <td>0.9941982670122679</td>\n",
       "      <td>0.002191118500689529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.7426803236905825</td>\n",
       "      <td>0.05730257639573962</td>\n",
       "      <td>0.9971776017432142</td>\n",
       "      <td>0.0007019732922477469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.7021942214292795</td>\n",
       "      <td>0.12292943240657711</td>\n",
       "      <td>0.9976478211789509</td>\n",
       "      <td>0.0012049527370182969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.7784574430426349</td>\n",
       "      <td>0.009331507956444399</td>\n",
       "      <td>0.9965506424955652</td>\n",
       "      <td>0.0012931063223858732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.7516248247737989</td>\n",
       "      <td>0.0565519880846663</td>\n",
       "      <td>0.9968639254571414</td>\n",
       "      <td>0.0009925534661854698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.7906763731362305</td>\n",
       "      <td>0.02454188970732176</td>\n",
       "      <td>0.9957660584558867</td>\n",
       "      <td>0.0025245171569931845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.7539753338147629</td>\n",
       "      <td>0.05259716683619898</td>\n",
       "      <td>0.9968640237882656</td>\n",
       "      <td>0.0010870608909753733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.6970117737847444</td>\n",
       "      <td>0.13605912005112733</td>\n",
       "      <td>0.9971774050809659</td>\n",
       "      <td>0.0015685978764482618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.7958535108958839</td>\n",
       "      <td>0.02160810972870626</td>\n",
       "      <td>0.9954525788320623</td>\n",
       "      <td>0.002485385616996313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">3</th>\n",
       "      <th>10</th>\n",
       "      <td>0.769983751752262</td>\n",
       "      <td>0.021888070054659724</td>\n",
       "      <td>0.9782062829655094</td>\n",
       "      <td>0.004573071466543406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.7817566515157952</td>\n",
       "      <td>0.025890396105114896</td>\n",
       "      <td>0.9963936076902806</td>\n",
       "      <td>0.001205247312455673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.6576071180776801</td>\n",
       "      <td>0.12165093972005821</td>\n",
       "      <td>0.9965503475021928</td>\n",
       "      <td>0.0016296830954453617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.7530053948430399</td>\n",
       "      <td>0.08318849703390518</td>\n",
       "      <td>0.9968640237882656</td>\n",
       "      <td>0.0006281392211388015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.734205747419396</td>\n",
       "      <td>0.07202850616880624</td>\n",
       "      <td>0.9967068906518567</td>\n",
       "      <td>0.0018494031149153174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.7864497047704005</td>\n",
       "      <td>0.02237561469159919</td>\n",
       "      <td>0.9963936076902806</td>\n",
       "      <td>0.001205247312455673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.7864461648471461</td>\n",
       "      <td>0.01065771819282287</td>\n",
       "      <td>0.9935717994202397</td>\n",
       "      <td>0.0027099725770728072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.6857158786797503</td>\n",
       "      <td>0.15143072119779924</td>\n",
       "      <td>0.9952958390201501</td>\n",
       "      <td>0.0025287687473253655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.7737643897880294</td>\n",
       "      <td>0.013073599488761462</td>\n",
       "      <td>0.9968638271260173</td>\n",
       "      <td>0.001255295131036005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.653309651246761</td>\n",
       "      <td>0.13701659386953888</td>\n",
       "      <td>0.9965503475021928</td>\n",
       "      <td>0.0011315215524325154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.7487813814196509</td>\n",
       "      <td>0.0708694612104884</td>\n",
       "      <td>0.996080029735332</td>\n",
       "      <td>0.0019013834303689065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">4</th>\n",
       "      <th>10</th>\n",
       "      <td>0.6071127677951943</td>\n",
       "      <td>0.25936706382800223</td>\n",
       "      <td>0.9873000436590191</td>\n",
       "      <td>0.005599274157370586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.6528547711085624</td>\n",
       "      <td>0.13739724736825978</td>\n",
       "      <td>0.9949825560585739</td>\n",
       "      <td>0.002304934046133085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.6323046316355861</td>\n",
       "      <td>0.23840662996356687</td>\n",
       "      <td>0.9915315269250284</td>\n",
       "      <td>0.00927916167824486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.7657570833864322</td>\n",
       "      <td>0.040462454007691585</td>\n",
       "      <td>0.9963933126969081</td>\n",
       "      <td>0.002321431141080094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.7219452232275605</td>\n",
       "      <td>0.1168757484859929</td>\n",
       "      <td>0.9948257179155375</td>\n",
       "      <td>0.0009288979589600803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.6536379791286125</td>\n",
       "      <td>0.28482003379430065</td>\n",
       "      <td>0.9951393942016102</td>\n",
       "      <td>0.002144111591857492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.7229222420457925</td>\n",
       "      <td>0.07333405764941701</td>\n",
       "      <td>0.9956102036240919</td>\n",
       "      <td>0.001172092592583011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.7007685173385442</td>\n",
       "      <td>0.1416313055082633</td>\n",
       "      <td>0.9948259145777858</td>\n",
       "      <td>0.0011198292892543036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.6965551236849185</td>\n",
       "      <td>0.11992366695264674</td>\n",
       "      <td>0.9960802263975803</td>\n",
       "      <td>0.0017388876969665888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.7272276737040341</td>\n",
       "      <td>0.069885809727548</td>\n",
       "      <td>0.9932583197964152</td>\n",
       "      <td>0.003387845662164985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.6148333404131798</td>\n",
       "      <td>0.18934662080462475</td>\n",
       "      <td>0.9951392958704861</td>\n",
       "      <td>0.002234703562263778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">5</th>\n",
       "      <th>10</th>\n",
       "      <td>0.6852353340979568</td>\n",
       "      <td>0.16493599010151133</td>\n",
       "      <td>0.9830660037837816</td>\n",
       "      <td>0.002809476826819518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.7422785424012008</td>\n",
       "      <td>0.058472370150527496</td>\n",
       "      <td>0.991689643372679</td>\n",
       "      <td>0.004099531712529887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.706543902128202</td>\n",
       "      <td>0.10708592535634136</td>\n",
       "      <td>0.9951389025459895</td>\n",
       "      <td>0.0030858644058463914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.6609213712246719</td>\n",
       "      <td>0.1445682816307662</td>\n",
       "      <td>0.9948257179155375</td>\n",
       "      <td>0.0021901119856472975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.6692251461988304</td>\n",
       "      <td>0.19504729225671463</td>\n",
       "      <td>0.9938850823818159</td>\n",
       "      <td>0.001428670533256856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.7930268821771944</td>\n",
       "      <td>0.016806086862901373</td>\n",
       "      <td>0.9910631757806507</td>\n",
       "      <td>0.0017937048962567027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.7196265734958867</td>\n",
       "      <td>0.077098191709756</td>\n",
       "      <td>0.9924732441011159</td>\n",
       "      <td>0.004369951262782177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.6194255058550331</td>\n",
       "      <td>0.18465190810321214</td>\n",
       "      <td>0.9937284409010277</td>\n",
       "      <td>0.002585449326376258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.7511548999617688</td>\n",
       "      <td>0.04394906456470769</td>\n",
       "      <td>0.9915329035607667</td>\n",
       "      <td>0.004102406761518719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.709258138283562</td>\n",
       "      <td>0.11320339533032604</td>\n",
       "      <td>0.9923166026203278</td>\n",
       "      <td>0.005065889741682065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.7897356385313566</td>\n",
       "      <td>0.019395779957374026</td>\n",
       "      <td>0.9937280475765311</td>\n",
       "      <td>0.0017752559873189656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Eficiencia en validacion  \\\n",
       "N. de capas ocultas Neuronas por capa                            \n",
       "1                   10                      0.6652055633433868   \n",
       "                    20                      0.7210168783540774   \n",
       "                    30                      0.6683578650014868   \n",
       "                    40                      0.7380262095917761   \n",
       "                    50                      0.7092492884754259   \n",
       "                    60                      0.7798672174787251   \n",
       "                    70                      0.7855133950695949   \n",
       "                    80                       0.775157349588661   \n",
       "                    90                      0.7247904365433357   \n",
       "                    100                     0.7393510258697592   \n",
       "                    120                     0.7652809637087069   \n",
       "2                   10                      0.6881805502456707   \n",
       "                    20                      0.6843583181116634   \n",
       "                    30                      0.7775113985528794   \n",
       "                    40                      0.7426803236905825   \n",
       "                    50                      0.7021942214292795   \n",
       "                    60                      0.7784574430426349   \n",
       "                    70                      0.7516248247737989   \n",
       "                    80                      0.7906763731362305   \n",
       "                    90                      0.7539753338147629   \n",
       "                    100                     0.6970117737847444   \n",
       "                    120                     0.7958535108958839   \n",
       "3                   10                       0.769983751752262   \n",
       "                    20                      0.7817566515157952   \n",
       "                    30                      0.6576071180776801   \n",
       "                    40                      0.7530053948430399   \n",
       "                    50                       0.734205747419396   \n",
       "                    60                      0.7864497047704005   \n",
       "                    70                      0.7864461648471461   \n",
       "                    80                      0.6857158786797503   \n",
       "                    90                      0.7737643897880294   \n",
       "                    100                      0.653309651246761   \n",
       "                    120                     0.7487813814196509   \n",
       "4                   10                      0.6071127677951943   \n",
       "                    20                      0.6528547711085624   \n",
       "                    30                      0.6323046316355861   \n",
       "                    40                      0.7657570833864322   \n",
       "                    50                      0.7219452232275605   \n",
       "                    60                      0.6536379791286125   \n",
       "                    70                      0.7229222420457925   \n",
       "                    80                      0.7007685173385442   \n",
       "                    90                      0.6965551236849185   \n",
       "                    100                     0.7272276737040341   \n",
       "                    120                     0.6148333404131798   \n",
       "5                   10                      0.6852353340979568   \n",
       "                    20                      0.7422785424012008   \n",
       "                    30                       0.706543902128202   \n",
       "                    40                      0.6609213712246719   \n",
       "                    50                      0.6692251461988304   \n",
       "                    60                      0.7930268821771944   \n",
       "                    70                      0.7196265734958867   \n",
       "                    80                      0.6194255058550331   \n",
       "                    90                      0.7511548999617688   \n",
       "                    100                      0.709258138283562   \n",
       "                    120                     0.7897356385313566   \n",
       "\n",
       "                                      IC Eficiencia en validacion  \\\n",
       "N. de capas ocultas Neuronas por capa                               \n",
       "1                   10                        0.19631049474871673   \n",
       "                    20                        0.10206166629413553   \n",
       "                    30                        0.12170345327133039   \n",
       "                    40                       0.049824030633566996   \n",
       "                    50                        0.11918509845590243   \n",
       "                    60                       0.003578027555392126   \n",
       "                    70                       0.005122875235273092   \n",
       "                    80                       0.012076023227392374   \n",
       "                    90                        0.08697479667501404   \n",
       "                    100                       0.10664634172965395   \n",
       "                    120                      0.016623763106296735   \n",
       "2                   10                         0.0936844064855061   \n",
       "                    20                        0.10224190717606721   \n",
       "                    30                       0.020707196349633954   \n",
       "                    40                        0.05730257639573962   \n",
       "                    50                        0.12292943240657711   \n",
       "                    60                       0.009331507956444399   \n",
       "                    70                         0.0565519880846663   \n",
       "                    80                        0.02454188970732176   \n",
       "                    90                        0.05259716683619898   \n",
       "                    100                       0.13605912005112733   \n",
       "                    120                       0.02160810972870626   \n",
       "3                   10                       0.021888070054659724   \n",
       "                    20                       0.025890396105114896   \n",
       "                    30                        0.12165093972005821   \n",
       "                    40                        0.08318849703390518   \n",
       "                    50                        0.07202850616880624   \n",
       "                    60                        0.02237561469159919   \n",
       "                    70                        0.01065771819282287   \n",
       "                    80                        0.15143072119779924   \n",
       "                    90                       0.013073599488761462   \n",
       "                    100                       0.13701659386953888   \n",
       "                    120                        0.0708694612104884   \n",
       "4                   10                        0.25936706382800223   \n",
       "                    20                        0.13739724736825978   \n",
       "                    30                        0.23840662996356687   \n",
       "                    40                       0.040462454007691585   \n",
       "                    50                         0.1168757484859929   \n",
       "                    60                        0.28482003379430065   \n",
       "                    70                        0.07333405764941701   \n",
       "                    80                         0.1416313055082633   \n",
       "                    90                        0.11992366695264674   \n",
       "                    100                         0.069885809727548   \n",
       "                    120                       0.18934662080462475   \n",
       "5                   10                        0.16493599010151133   \n",
       "                    20                       0.058472370150527496   \n",
       "                    30                        0.10708592535634136   \n",
       "                    40                         0.1445682816307662   \n",
       "                    50                        0.19504729225671463   \n",
       "                    60                       0.016806086862901373   \n",
       "                    70                          0.077098191709756   \n",
       "                    80                        0.18465190810321214   \n",
       "                    90                        0.04394906456470769   \n",
       "                    100                       0.11320339533032604   \n",
       "                    120                      0.019395779957374026   \n",
       "\n",
       "                                      Eficiencia en entrenamiento  \\\n",
       "N. de capas ocultas Neuronas por capa                               \n",
       "1                   10                         0.9628392915439167   \n",
       "                    20                         0.9819681367825269   \n",
       "                    30                         0.9909062393064901   \n",
       "                    40                         0.9929435618679767   \n",
       "                    50                         0.9924737357567366   \n",
       "                    60                          0.995923388254544   \n",
       "                    70                         0.9941985620056404   \n",
       "                    80                         0.9938848857195675   \n",
       "                    90                         0.9943557934731733   \n",
       "                    100                        0.9965503475021928   \n",
       "                    120                        0.9957661567870109   \n",
       "2                   10                          0.986045338514728   \n",
       "                    20                         0.9951390008771137   \n",
       "                    30                         0.9941982670122679   \n",
       "                    40                         0.9971776017432142   \n",
       "                    50                         0.9976478211789509   \n",
       "                    60                         0.9965506424955652   \n",
       "                    70                         0.9968639254571414   \n",
       "                    80                         0.9957660584558867   \n",
       "                    90                         0.9968640237882656   \n",
       "                    100                        0.9971774050809659   \n",
       "                    120                        0.9954525788320623   \n",
       "3                   10                         0.9782062829655094   \n",
       "                    20                         0.9963936076902806   \n",
       "                    30                         0.9965503475021928   \n",
       "                    40                         0.9968640237882656   \n",
       "                    50                         0.9967068906518567   \n",
       "                    60                         0.9963936076902806   \n",
       "                    70                         0.9935717994202397   \n",
       "                    80                         0.9952958390201501   \n",
       "                    90                         0.9968638271260173   \n",
       "                    100                        0.9965503475021928   \n",
       "                    120                         0.996080029735332   \n",
       "4                   10                         0.9873000436590191   \n",
       "                    20                         0.9949825560585739   \n",
       "                    30                         0.9915315269250284   \n",
       "                    40                         0.9963933126969081   \n",
       "                    50                         0.9948257179155375   \n",
       "                    60                         0.9951393942016102   \n",
       "                    70                         0.9956102036240919   \n",
       "                    80                         0.9948259145777858   \n",
       "                    90                         0.9960802263975803   \n",
       "                    100                        0.9932583197964152   \n",
       "                    120                        0.9951392958704861   \n",
       "5                   10                         0.9830660037837816   \n",
       "                    20                          0.991689643372679   \n",
       "                    30                         0.9951389025459895   \n",
       "                    40                         0.9948257179155375   \n",
       "                    50                         0.9938850823818159   \n",
       "                    60                         0.9910631757806507   \n",
       "                    70                         0.9924732441011159   \n",
       "                    80                         0.9937284409010277   \n",
       "                    90                         0.9915329035607667   \n",
       "                    100                        0.9923166026203278   \n",
       "                    120                        0.9937280475765311   \n",
       "\n",
       "                                      IC Eficiencia en entrenamiento  \n",
       "N. de capas ocultas Neuronas por capa                                 \n",
       "1                   10                          0.006885487312743781  \n",
       "                    20                          0.005294735088287567  \n",
       "                    30                          0.000701363333026307  \n",
       "                    40                          0.003022166742979009  \n",
       "                    50                          0.002173441307030737  \n",
       "                    60                         0.0005439853757911653  \n",
       "                    70                          0.002563238232641931  \n",
       "                    80                          0.002484238133809588  \n",
       "                    90                         0.0011721983651877639  \n",
       "                    100                        0.0011315215524325154  \n",
       "                    120                        0.0020513461268557376  \n",
       "2                   10                         0.0022804283621258126  \n",
       "                    20                         0.0017959709781269419  \n",
       "                    30                          0.002191118500689529  \n",
       "                    40                         0.0007019732922477469  \n",
       "                    50                         0.0012049527370182969  \n",
       "                    60                         0.0012931063223858732  \n",
       "                    70                         0.0009925534661854698  \n",
       "                    80                         0.0025245171569931845  \n",
       "                    90                         0.0010870608909753733  \n",
       "                    100                        0.0015685978764482618  \n",
       "                    120                         0.002485385616996313  \n",
       "3                   10                          0.004573071466543406  \n",
       "                    20                          0.001205247312455673  \n",
       "                    30                         0.0016296830954453617  \n",
       "                    40                         0.0006281392211388015  \n",
       "                    50                         0.0018494031149153174  \n",
       "                    60                          0.001205247312455673  \n",
       "                    70                         0.0027099725770728072  \n",
       "                    80                         0.0025287687473253655  \n",
       "                    90                          0.001255295131036005  \n",
       "                    100                        0.0011315215524325154  \n",
       "                    120                        0.0019013834303689065  \n",
       "4                   10                          0.005599274157370586  \n",
       "                    20                          0.002304934046133085  \n",
       "                    30                           0.00927916167824486  \n",
       "                    40                          0.002321431141080094  \n",
       "                    50                         0.0009288979589600803  \n",
       "                    60                          0.002144111591857492  \n",
       "                    70                          0.001172092592583011  \n",
       "                    80                         0.0011198292892543036  \n",
       "                    90                         0.0017388876969665888  \n",
       "                    100                         0.003387845662164985  \n",
       "                    120                         0.002234703562263778  \n",
       "5                   10                          0.002809476826819518  \n",
       "                    20                          0.004099531712529887  \n",
       "                    30                         0.0030858644058463914  \n",
       "                    40                         0.0021901119856472975  \n",
       "                    50                          0.001428670533256856  \n",
       "                    60                         0.0017937048962567027  \n",
       "                    70                          0.004369951262782177  \n",
       "                    80                          0.002585449326376258  \n",
       "                    90                          0.004102406761518719  \n",
       "                    100                         0.005065889741682065  \n",
       "                    120                        0.0017752559873189656  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cap,neu in df_types.index:\n",
    "    eficiencia_val, ic_val,error, std_error=redes_neuronales(neuronas=neu,capas_ocultas=cap)\n",
    "    df_types[\"Eficiencia en validacion\"][cap,neu] = str(eficiencia_val) \n",
    "    df_types[\"IC Eficiencia en validacion\"][cap,neu] = str(ic_val)\n",
    "    df_types[\"Eficiencia en entrenamiento\"][cap,neu] = str(error)\n",
    "    df_types[\"IC Eficiencia en entrenamiento\"][cap,neu] = str(std_error)\n",
    "df_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
